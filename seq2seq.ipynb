{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "seq2seq",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsX0L1sG1iZj"
      },
      "source": [
        "## Neural translation model - English to German Translation using seq2seq model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VyTvxPN1iZn"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import unicodedata\n",
        "import re\n",
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9Dq6vv3FVO"
      },
      "source": [
        "##Data import\n",
        "\n",
        "Dataset downlad link:\n",
        "\n",
        "https://drive.google.com/open?id=1KczOciG7sYY7SB9UlBeRP1T9659b121Q\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8PetPpw1iZu"
      },
      "source": [
        "# load the dataset\n",
        "NUM_EXAMPLES = 20000\n",
        "data_examples = []\n",
        "with open('./deu.txt', 'r', encoding='utf8') as f:\n",
        "    for line in f.readlines():\n",
        "        if len(data_examples) < NUM_EXAMPLES:\n",
        "            data_examples.append(line)\n",
        "        else:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JumLjJ631iZy"
      },
      "source": [
        "# Preprocess English and German sentences\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"ü\", 'ue', sentence)\n",
        "    sentence = re.sub(r\"ä\", 'ae', sentence)\n",
        "    sentence = re.sub(r\"ö\", 'oe', sentence)\n",
        "    sentence = re.sub(r'ß', 'ss', sentence)\n",
        "    \n",
        "    sentence = unicode_to_ascii(sentence)\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r\"[^a-z?.!,']+\", \" \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    \n",
        "    return sentence.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z70nu6_01iZ3"
      },
      "source": [
        "\n",
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9G20C4bk1iZ4"
      },
      "source": [
        "# separates list of english and german sentences and preprosess them\n",
        "def get_sentence(data_examples):\n",
        "    english_sentence = []\n",
        "    german_sentence = []\n",
        "    for line in data_examples:\n",
        "        temp_list = line.strip().split('\\t')\n",
        "        english_sentence.append(preprocess_sentence(temp_list[0]))\n",
        "      Import the data  german_sentence.append(preprocess_sentence(temp_list[1]))\n",
        "    return english_sentence, german_sentence\n",
        "\n",
        "english_sentences, german_sentences = get_sentence(data_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEdfKMhEs-MR"
      },
      "source": [
        "# Add a special \"<start>\" and \"<end>\" token to the beginning and end of every German sentence.\n",
        "def add_start_and_end_token(german_sentences):\n",
        "    start_token = '<start> '\n",
        "    end_token = ' <end>'\n",
        "    return [start_token + line + end_token for line in german_sentences]\n",
        "\n",
        "german_sentences_with_token = add_start_and_end_token(german_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAIUW8Og0dRE"
      },
      "source": [
        "# tokenize the German sentences\n",
        "def get_tokenizer(sentences):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    return tokenizer\n",
        "german_tokenizer = get_tokenizer(german_sentences_with_token)\n",
        "german_tokenizer_max_index = max(german_tokenizer.index_word.keys())\n",
        "german_seq = german_tokenizer.texts_to_sequences(german_sentences_with_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO_IT1j96S7v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "9705725c-56e8-4e03-c1ae-44ac9c6f32d0"
      },
      "source": [
        "# 5 randomly chosen examples of (preprocessed) English and German sentence pairs.\n",
        "idx = tf.random.uniform((5,), minval=0, maxval=len(german_seq), dtype=tf.int32).numpy()\n",
        "for i, id in enumerate(idx):\n",
        "    if i != 0:\n",
        "        print('\\n==================================================================================\\n')\n",
        "\n",
        "    print(f'English translation: {english_sentences[id]}')\n",
        "    print(f'German translation: {german_sentences_with_token[id]}')\n",
        "    print(f'German tokenized sequence: {german_seq[id]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English translation: that's very big .\n",
            "German translation: <start> das ist enorm . <end>\n",
            "German tokenized sequence: [1, 11, 6, 1867, 3, 2]\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "English translation: we'll be ok .\n",
            "German translation: <start> wir werden okay sein . <end>\n",
            "German tokenized sequence: [1, 17, 69, 231, 54, 3, 2]\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "English translation: i'm all alone now .\n",
            "German translation: <start> jetzt bin ich ganz allein . <end>\n",
            "German tokenized sequence: [1, 62, 15, 4, 194, 139, 3, 2]\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "English translation: they won't know .\n",
            "German translation: <start> sie werden es nicht wissen . <end>\n",
            "German tokenized sequence: [1, 8, 69, 10, 12, 191, 3, 2]\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "English translation: he winked at her .\n",
            "German translation: <start> er zwinkerte ihr zu . <end>\n",
            "German tokenized sequence: [1, 14, 1276, 27, 20, 3, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHbziF9K9ISq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01acb3e1-fb0c-466a-afca-a182fe64747e"
      },
      "source": [
        "# Pads the end of the tokenized German sequences with zeros, and batch the complete set of sequences into one numpy array.\n",
        "german_padded_seq = tf.keras.preprocessing.sequence.pad_sequences(german_seq, padding='post')\n",
        "print(f'german_padded_seq.shape = {german_padded_seq.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "german_padded_seq.shape = (20000, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foL7Ihs21iaP"
      },
      "source": [
        "##Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywZgobCh1iaR"
      },
      "source": [
        "# Load embedding module from Tensorflow Hub\n",
        "\n",
        "embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\", \n",
        "                                 output_shape=[128], input_shape=[], dtype=tf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiY8QEDp1iaV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1c72ca83-4e3e-4dae-be88-cc1980b034f1"
      },
      "source": [
        "# Test the layer\n",
        "embedding_layer(tf.constant([\"these\", \"aren't\", \"the\", \"droids\", \"you're\", \"looking\", \"for\"])).shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc78facc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc78facc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-BUJOl_1iaZ"
      },
      "source": [
        "# Creates a random training and validation set split of the data, reserving 20% of the data for validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split = train_test_split(english_sentences, german_padded_seq, test_size=0.2)\n",
        "english_sentences_train, english_sentences_test = split[:2]\n",
        "german_padded_seq_train, german_padded_seq_test = split[2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w6rM8Bl1iad"
      },
      "source": [
        "# Loads the training and validation sets into a tf.data.Dataset object, passing in a tuple of English and German data for both training and validation sets.\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices((english_sentences_train, german_padded_seq_train))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((english_sentences_test, german_padded_seq_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGqlxuqZ1ias"
      },
      "source": [
        "# function to map over the datasets that splits each English sentence at spaces.\n",
        "def split_english_sentences(dataset):\n",
        "    def func(english_sentence, german_padded_seq):\n",
        "        return tf.strings.split(english_sentence), german_padded_seq\n",
        "    dataset = dataset.map(func)\n",
        "    return dataset\n",
        "    \n",
        "training_dataset = split_english_sentences(training_dataset)\n",
        "validation_dataset = split_english_sentences(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDPkbOx7rR3o"
      },
      "source": [
        "# function to map over the datasets that embeds each sequence of English words using the loaded embedding layer/model.\n",
        "def embed_english_words(dataset, embedding_layer):\n",
        "    dataset = dataset.map(lambda x,y: (embedding_layer(x), y))\n",
        "    return dataset\n",
        "    \n",
        "training_dataset = embed_english_words(training_dataset, embedding_layer)\n",
        "validation_dataset = embed_english_words(validation_dataset, embedding_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdqSXEoX1iav"
      },
      "source": [
        "# function to filter out dataset examples where the English sentence is more than 13 (embedded) tokens in length. \n",
        "def filter_english_seq(dataset):\n",
        "    dataset = dataset.filter(lambda x,y: len(x) <= 13)\n",
        "    return dataset\n",
        "  \n",
        "training_dataset = filter_english_seq(training_dataset)\n",
        "validation_dataset = filter_english_seq(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpQdGn9sBw2-"
      },
      "source": [
        "# function to map over the datasets that pads each English sequence of embeddings with \n",
        "# some distinct padding value before the sequence, so that each sequence is length 13.\n",
        "def pad_english_seq(dataset):\n",
        "    def func(x, y):\n",
        "        x = tf.pad(x, paddings=[[13 - tf.shape(x)[0], 0],[0,0]], constant_values=0)\n",
        "        return x,y\n",
        "    dataset = dataset.map(func)\n",
        "    return dataset\n",
        "\n",
        "training_dataset = pad_english_seq(training_dataset)\n",
        "validation_dataset = pad_english_seq(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KTOK1F2o5ye"
      },
      "source": [
        "# Batches both training and validation Datasets with a batch size of 16\n",
        "def get_batched_dataset(dataset, training=False, batch_size=16):\n",
        "    if training:\n",
        "      dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "training_batched_dataset = get_batched_dataset(training_dataset, training=True)\n",
        "validation_batched_dataset = get_batched_dataset(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHB7YcXN6Zil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "84d00c33-49c2-4277-ab79-2a433396a607"
      },
      "source": [
        "# element_spec property for the training and validation Dataset\n",
        "print(f'training_batched_dataset.element_spec = {training_batched_dataset.element_spec}')\n",
        "print(f'validation_batched_dataset.element_spec = {validation_batched_dataset.element_spec}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_batched_dataset.element_spec = (TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 14), dtype=tf.int32, name=None))\n",
            "validation_batched_dataset.element_spec = (TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 14), dtype=tf.int32, name=None))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re_kZCgV7NLR"
      },
      "source": [
        "english_batch, german_batch = next(iter(training_batched_dataset.take(1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC1sZV6p7ALj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7639a826-272d-405d-8aff-8741a08e6b94"
      },
      "source": [
        "# shape of the English data example from the training Dataset.\n",
        "print(f'shape of the English data example = {english_batch.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the English data example = (16, 13, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsCKnnku7xID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "9cf954a3-11be-4c44-81c3-c5267ff654ad"
      },
      "source": [
        "# German data example Tensor from the validation Dataset.\n",
        "print(f'shape of the German data example = \\n{german_batch}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the German data example = \n",
            "[[   1    4   66   60  382    3    2    0    0    0    0    0    0    0]\n",
            " [   1    5    6   19 4516    3    2    0    0    0    0    0    0    0]\n",
            " [   1    6   11   19 1654    7    2    0    0    0    0    0    0    0]\n",
            " [   1    4  503   38 5600  475    3    2    0    0    0    0    0    0]\n",
            " [   1   86    8   26  215   29    3    2    0    0    0    0    0    0]\n",
            " [   1   13   32 3758    3    2    0    0    0    0    0    0    0    0]\n",
            " [   1   11  148   21    3    2    0    0    0    0    0    0    0    0]\n",
            " [   1    4  122 2202    3    2    0    0    0    0    0    0    0    0]\n",
            " [   1   11    6   19  113    3    2    0    0    0    0    0    0    0]\n",
            " [   1   17   69 3741    3    2    0    0    0    0    0    0    0    0]\n",
            " [   1 2362   37 1835    3    2    0    0    0    0    0    0    0    0]\n",
            " [   1   14 2234 2851    3    2    0    0    0    0    0    0    0    0]\n",
            " [   1    5  416  149  368    3    2    0    0    0    0    0    0    0]\n",
            " [   1    5  105   10   12   49    3    2    0    0    0    0    0    0]\n",
            " [   1 2654   28   12    3    2    0    0    0    0    0    0    0    0]\n",
            " [   1   11    6 1324    3    2    0    0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isIYhjq01iay"
      },
      "source": [
        "## Custom layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg9hjZz11ia0"
      },
      "source": [
        "# layer that takes a batch of English data examples from one of the \n",
        "# Datasets, and adds a learned embedded ‘end’ token to the end of each sequence. \n",
        "class EndTokenEmbeddingLayer(tf.keras.layers.Layer):\n",
        "  \n",
        "    def __init__(self, **kwargs):\n",
        "        super(EndTokenEmbeddingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        initializer = tf.random_normal_initializer()\n",
        "        self.embedding = tf.Variable(initial_value=initializer(shape=(input_shape[-1],)))\n",
        "\n",
        "    def call(self, input):\n",
        "        x = tf.map_fn(lambda x: tf.concat([x, tf.reshape(tf.convert_to_tensor(self.embedding), (1,-1))], axis=0), input)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7oUT8278kIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4710aebd-c659-4400-ae35-0d338ac90a52"
      },
      "source": [
        "english_batch, german_batch = next(iter(training_batched_dataset.take(1)))\n",
        "print(f'shape after passing through EndTokenEmbeddingLayer = {EndTokenEmbeddingLayer()(english_batch).shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape after passing through EndTokenEmbeddingLayer = (16, 14, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAd3i4_y1ia-"
      },
      "source": [
        "## Encoder network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R2LqbfV1ia_"
      },
      "source": [
        "def get_encoder(input_shape):\n",
        "\n",
        "    model_input = tf.keras.Input(shape=input_shape, name='input')\n",
        "    x = EndTokenEmbeddingLayer(name='end_token_embedding_layer')(model_input)\n",
        "    x = tf.keras.layers.Masking(name='masking_layer')(x)\n",
        "    output, hidden_state, cell_state = tf.keras.layers.LSTM(512, return_state=True, name='lstm')(x)\n",
        "    model = tf.keras.models.Model(inputs=model_input, outputs=[hidden_state, cell_state], name='Encoder')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDwIW6l-DVhk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a7504f88-00c7-4f34-d772-7f7362ca2ee7"
      },
      "source": [
        "encoder = get_encoder((None, 128))\n",
        "\n",
        "english_batch, german_batch = next(iter(training_batched_dataset.take(1)))\n",
        "\n",
        "hidden_state, cell_state = encoder(english_batch)\n",
        "\n",
        "print(f'hidden_state shape: {hidden_state.shape}')\n",
        "print(f'cell_state shape: {cell_state.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden_state shape: (16, 512)\n",
            "cell_state shape: (16, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEk9ikVh1ibL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b83b7ec5-f6bb-4a66-c0bb-a12999c668a5"
      },
      "source": [
        "# model summary for the encoder network.\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, None, 128)]       0         \n",
            "_________________________________________________________________\n",
            "end_token_embedding_layer (E (None, None, 128)         128       \n",
            "_________________________________________________________________\n",
            "masking_layer (Masking)      (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 512), (None, 512) 1312768   \n",
            "=================================================================\n",
            "Total params: 1,312,896\n",
            "Trainable params: 1,312,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvkzpCeZ1ibR"
      },
      "source": [
        "##Decoder network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l50qhnXD1ibT"
      },
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "\n",
        "    def __init__(self, german_tokenizer_max_index,**kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        self.embedding = tf.keras.layers.Embedding(german_tokenizer_max_index + 1, 128, mask_zero=True, name='embedding')\n",
        "        self.lstm = tf.keras.layers.LSTM(512, return_state=True, return_sequences=True, name='lstm')\n",
        "        self.dense = tf.keras.layers.Dense(german_tokenizer_max_index + 1, name='dense')\n",
        "        \n",
        "    def call(self, inputs, hidden_state, cell_state):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.lstm(x, initial_state=[hidden_state, cell_state])\n",
        "        return self.dense(x[0]), x[1], x[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1QbVGo80BQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d4532f54-3aae-49e0-cc29-692f6f972a30"
      },
      "source": [
        "english_batch, german_batch = next(iter(training_batched_dataset.take(1)))\n",
        "\n",
        "encoder = get_encoder((None, 128))\n",
        "hidden_state, cell_state = encoder(english_batch)\n",
        "\n",
        "decoder = Decoder(german_tokenizer_max_index, name='Decoder')\n",
        "output, hidden_state, cell_state = decoder(german_batch, hidden_state, cell_state)\n",
        "\n",
        "print(f'output shape: {output.shape}')\n",
        "print(f'hidden_state shape: {hidden_state.shape}')\n",
        "print(f'cell_state shape: {cell_state.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output shape: (16, 14, 5744)\n",
            "hidden_state shape: (16, 512)\n",
            "cell_state shape: (16, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFYU5-XezuKM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "8ca19b13-230c-4e24-c846-b051bb847756"
      },
      "source": [
        "# model summary for the decoder network\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  735232    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  1312768   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  2946672   \n",
            "=================================================================\n",
            "Total params: 4,994,672\n",
            "Trainable params: 4,994,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pST9XGJ81ibo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hJHbWqs1ibr"
      },
      "source": [
        "# function that takes a Tensor batch of German data (as extracted from the \n",
        "# training Dataset), and returns a tuple containing German inputs and outputs for the decoder model\n",
        "\n",
        "def get_german_data(batch_data):\n",
        "    return batch_data[:,:-1], batch_data[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVDPbZwUSKYN"
      },
      "source": [
        "# computes the forward and backward pass for your translation model.\n",
        "\n",
        "@tf.function\n",
        "def propogate(english_input, german_input, german_output, encoder, decoder, loss_fn):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      encoder_hidden_state, encoder_cell_state = encoder(english_input)\n",
        "      decoder_return_sequence, _, _ = decoder(german_input, encoder_hidden_state, encoder_cell_state)      \n",
        "      loss = loss_fn(german_output, decoder_return_sequence)\n",
        "    return loss, tape.gradient(loss, [encoder.trainable_variables, decoder.trainable_variables])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVWOYJ3l1ib1"
      },
      "source": [
        "# custom training loop\n",
        "\n",
        "def train(encoder, decoder, num_epochs, training_batched_dataset, validation_batched_dataset, patience):\n",
        "\n",
        "    training_epochs_losses = []\n",
        "    validation_epochs_losses = []\n",
        "\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    patience_count = 0\n",
        "    for i in range(num_epochs):\n",
        "        \n",
        "        training_epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "        validation_epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "        for english, german in training_batched_dataset.as_numpy_iterator():\n",
        "\n",
        "            german_input, german_output = get_german_data(german)\n",
        "            loss, [encoder_gradient, decoder_gradient] = propogate(english, german_input, german_output, encoder, decoder, loss_fn)\n",
        "            training_epoch_loss_avg(loss)\n",
        "            optimizer.apply_gradients(zip(encoder_gradient, encoder.trainable_variables))\n",
        "            optimizer.apply_gradients(zip(decoder_gradient, decoder.trainable_variables))\n",
        "\n",
        "        for english, german in validation_batched_dataset:\n",
        "\n",
        "            german_input, german_output = get_german_data(german)\n",
        "            encoder_hidden_state, encoder_cell_state = encoder(english)\n",
        "            decoder_return_sequence, _, _ = decoder(german_input, encoder_hidden_state, encoder_cell_state)\n",
        "            validation_epoch_loss_avg(loss_fn(german_output, decoder_return_sequence))\n",
        "\n",
        "\n",
        "        validation_epoch_loss = validation_epoch_loss_avg.result().numpy()\n",
        "\n",
        "        if not validation_epochs_losses or validation_epoch_loss < min(validation_epochs_losses):\n",
        "            print('saving best weights')\n",
        "            encoder.save_weights('./encoder/checkpoint')\n",
        "            decoder.save_weights('./decoder/checkpoint')\n",
        "\n",
        "        if validation_epochs_losses and validation_epoch_loss > min(validation_epochs_losses):\n",
        "            patience_count += 1\n",
        "        else:\n",
        "            patience_count = 0\n",
        "\n",
        "        if patience_count > patience:\n",
        "            break\n",
        "\n",
        "        validation_epochs_losses.append(validation_epoch_loss)\n",
        "\n",
        "        training_epoch_loss = training_epoch_loss_avg.result().numpy()\n",
        "        training_epochs_losses.append(training_epoch_loss)\n",
        "        \n",
        "\n",
        "        print(f'epoch: {i+1}/{num_epochs}, loss: {round(training_epoch_loss, 2)}, val_loss: {round(validation_epoch_loss, 2)}')\n",
        "        if patience_count > patience:\n",
        "            break\n",
        "    \n",
        "    return training_epochs_losses, validation_epochs_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKVbRqxWZld-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "0bcb3d5f-1e31-4b0c-93ce-5db37094a453"
      },
      "source": [
        "encoder = get_encoder(input_shape=(None, 128))\n",
        "decoder = Decoder(german_tokenizer_max_index)\n",
        "num_epochs = 15\n",
        "patience = 1\n",
        "\n",
        "training_batched_dataset = get_batched_dataset(training_dataset, training=True)\n",
        "validation_batched_dataset = get_batched_dataset(validation_dataset)\n",
        "\n",
        "training_epochs_losses, validation_epoch_losses = train(encoder, decoder, num_epochs, training_batched_dataset, validation_batched_dataset, patience)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving best weights\n",
            "epoch: 1/15, loss: 5.320000171661377, val_loss: 4.579999923706055\n",
            "saving best weights\n",
            "epoch: 2/15, loss: 4.03000020980835, val_loss: 3.680000066757202\n",
            "saving best weights\n",
            "epoch: 3/15, loss: 3.0999999046325684, val_loss: 2.9200000762939453\n",
            "saving best weights\n",
            "epoch: 4/15, loss: 2.2799999713897705, val_loss: 2.259999990463257\n",
            "saving best weights\n",
            "epoch: 5/15, loss: 1.5700000524520874, val_loss: 1.7200000286102295\n",
            "saving best weights\n",
            "epoch: 6/15, loss: 1.0199999809265137, val_loss: 1.350000023841858\n",
            "saving best weights\n",
            "epoch: 7/15, loss: 0.6600000262260437, val_loss: 1.149999976158142\n",
            "saving best weights\n",
            "epoch: 8/15, loss: 0.46000000834465027, val_loss: 1.0499999523162842\n",
            "saving best weights\n",
            "epoch: 9/15, loss: 0.33000001311302185, val_loss: 1.0099999904632568\n",
            "saving best weights\n",
            "epoch: 10/15, loss: 0.25, val_loss: 0.9900000095367432\n",
            "saving best weights\n",
            "epoch: 11/15, loss: 0.20000000298023224, val_loss: 0.9800000190734863\n",
            "epoch: 12/15, loss: 0.17000000178813934, val_loss: 0.9900000095367432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgyayfBziKPq"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpacst2F1ib7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "a0715b41-3f39-4488-b239-3a43d0abdb37"
      },
      "source": [
        "# loss vs epoch for both training and validation sets.\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(training_epochs_losses)\n",
        "plt.plot(validation_epoch_losses)\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.title('Loss v/s epochs');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM2gvBM11ib-"
      },
      "source": [
        "##Translate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGnQtE7L1icA"
      },
      "source": [
        "# five randomly sampled English sentences\n",
        "english_sentences, german_sentences = get_sentence(data_examples)\n",
        "idx = tf.random.uniform((5,), minval=0, maxval=len(english_sentences), dtype=tf.int32).numpy()\n",
        "\n",
        "five_english_sentences , five_german_sentences = [], []\n",
        "\n",
        "for id in idx:\n",
        "    five_english_sentences.append(english_sentences[id])\n",
        "    five_german_sentences.append(german_sentences[id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohleJRcJ1icD"
      },
      "source": [
        "# Preprocess and embed the English sentence according to the model requirements.\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((five_english_sentences, five_german_sentences))\n",
        "test_dataset = split_english_sentences(test_dataset)\n",
        "test_dataset = embed_english_words(test_dataset, embedding_layer)\n",
        "test_dataset = filter_english_seq(test_dataset)\n",
        "test_dadaset = pad_english_seq(test_dataset)\n",
        "test_dataset = get_batched_dataset(test_dataset, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unk60cEy1icI"
      },
      "source": [
        "# Pass the embedded sentence through the encoder to get the encoder hidden and cell states.\n",
        "states = []\n",
        "for english_data in test_dataset:\n",
        "    states.append(encoder(english_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo-yyzs6xCWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "7e744e32-b3e3-4d97-8708-8c128bcbc68e"
      },
      "source": [
        "# Decode the output token sequence into German text and print the English text and the model's German translation.\n",
        "start_token = german_tokenizer.word_index['<start>']\n",
        "end_token = german_tokenizer.word_index['<end>']\n",
        "\n",
        "for i in range(5):\n",
        "    if i != 0:\n",
        "        print('\\n==================================================================================\\n')\n",
        "    decoder_output = []\n",
        "    hidden_state, cell_state = states[i][0], states[i][1]\n",
        "    token = start_token\n",
        "    for j in range(14):\n",
        "      token = tf.constant([[token]], dtype=tf.float32)\n",
        "      logit, hidden_state, cell_state = decoder(token, hidden_state, cell_state)\n",
        "      token = tf.argmax(logit[0][0]).numpy()\n",
        "      if token == end_token:\n",
        "        break\n",
        "      decoder_output.append(token)\n",
        "\n",
        "    print(f'english sentence             : {five_english_sentences[i]}')\n",
        "    print(f'labeled german translation   : {five_german_sentences[i]}')\n",
        "    print(f'predicted german translation : {\" \".join([german_tokenizer.index_word[token] for token in decoder_output])}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english sentence             : can it be true ?\n",
            "labeled german translation   : kann es stimmen ?\n",
            "predicted german translation : kann es stimmen ?\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "english sentence             : no one flinched .\n",
            "labeled german translation   : niemand wich zurueck .\n",
            "predicted german translation : niemand wich zurueck .\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "english sentence             : come down here .\n",
            "labeled german translation   : kommen sie hier herunter !\n",
            "predicted german translation : komm her .\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "english sentence             : i worked at it .\n",
            "labeled german translation   : ich habe daran gearbeitet .\n",
            "predicted german translation : ich habe das gemacht .\n",
            "\n",
            "==================================================================================\n",
            "\n",
            "english sentence             : it's inhumane .\n",
            "labeled german translation   : das ist unmenschlich .\n",
            "predicted german translation : das ist unmoralisch .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}